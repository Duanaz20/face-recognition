{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12347836,"sourceType":"datasetVersion","datasetId":7784324}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Load important libraries\nimport pandas as pd\nimport numpy as np\n\nfrom glob import glob\n\nimport cv2,os\nimport matplotlib.pylab as plt\n\n# for better visuals\nplt.style.use('ggplot')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T16:44:53.641247Z","iopub.execute_input":"2025-07-05T16:44:53.641934Z","iopub.status.idle":"2025-07-05T16:44:54.162086Z","shell.execute_reply.started":"2025-07-05T16:44:53.641910Z","shell.execute_reply":"2025-07-05T16:44:54.161548Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load OpenCV's pre-trained face detector\nface_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T16:44:54.163307Z","iopub.execute_input":"2025-07-05T16:44:54.163859Z","iopub.status.idle":"2025-07-05T16:44:54.193473Z","shell.execute_reply.started":"2025-07-05T16:44:54.163838Z","shell.execute_reply":"2025-07-05T16:44:54.193017Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_path = '../input/students-images/'\nstudent_ids = sorted(os.listdir(base_path))\n\nall_faces = []\nlabels = []\ncounts = {}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T16:44:54.194084Z","iopub.execute_input":"2025-07-05T16:44:54.194250Z","iopub.status.idle":"2025-07-05T16:44:54.205507Z","shell.execute_reply.started":"2025-07-05T16:44:54.194236Z","shell.execute_reply":"2025-07-05T16:44:54.204935Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize 1 face per student\nplt.figure(figsize=(15, 6))\n\nfor idx, student_id in enumerate(student_ids):\n    image_folder = os.path.join(base_path, student_id, student_id)\n    image_paths = sorted(glob(os.path.join(image_folder, '*.jpg')))\n    counts[student_id] = len(image_paths)\n\n    # Show 1 raw image and 1 face\n    if idx < 12:  # display all\n        img = cv2.imread(image_paths[0])\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n\n        # Try detecting face\n        if len(faces) > 0:\n            (x, y, w, h) = faces[0]\n            face = gray[y:y+h, x:x+w]\n            face = cv2.resize(face, (100, 100))\n        else:\n            face = cv2.resize(gray, (100, 100))  # fallback\n\n        # Show extracted face\n        plt.subplot(2, 6, idx+1)\n        plt.imshow(face, cmap='gray')\n        plt.title(f'Student {student_id}')\n        plt.axis('off')\n\nplt.suptitle('One Face per Student (Grayscale, Cropped)')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T16:44:54.206899Z","iopub.execute_input":"2025-07-05T16:44:54.207065Z","iopub.status.idle":"2025-07-05T16:44:57.575172Z","shell.execute_reply.started":"2025-07-05T16:44:54.207051Z","shell.execute_reply":"2025-07-05T16:44:57.574470Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display number of images per student\ncount_df = pd.DataFrame.from_dict(counts, orient='index', columns=['# Images'])\nprint(count_df)\n\n# Bar plot\ncount_df.plot(kind='bar', legend=False, figsize=(10, 4), title=\"Image Count per Student\")\nplt.ylabel(\"Number of Images\")\nplt.xticks(rotation=0)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T16:44:57.575946Z","iopub.execute_input":"2025-07-05T16:44:57.576176Z","iopub.status.idle":"2025-07-05T16:44:57.783510Z","shell.execute_reply.started":"2025-07-05T16:44:57.576158Z","shell.execute_reply":"2025-07-05T16:44:57.782877Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# extracting all faces and labels in all_faces[] and labels[] array\nprint(\"Extracting all faces and labels...\")\n\nfor student_id in student_ids:\n    image_folder = os.path.join(base_path, student_id, student_id)\n    image_paths = sorted(glob(os.path.join(image_folder, '*.jpg')))\n\n    for path in image_paths:\n        img = cv2.imread(path)\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n\n        # If a face is detected, extract the first one\n        if len(faces) > 0:\n            (x, y, w, h) = faces[0]\n            face = gray[y:y+h, x:x+w]\n            face = cv2.resize(face, (100, 100))\n            all_faces.append(face.flatten())\n            labels.append(student_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T16:44:57.784155Z","iopub.execute_input":"2025-07-05T16:44:57.784333Z","iopub.status.idle":"2025-07-05T16:55:43.253851Z","shell.execute_reply.started":"2025-07-05T16:44:57.784318Z","shell.execute_reply":"2025-07-05T16:55:43.253247Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# test code\nprint(\"Total faces extracted:\", len(all_faces))\nprint(\"Total labels collected:\", len(labels))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T16:55:43.254584Z","iopub.execute_input":"2025-07-05T16:55:43.254785Z","iopub.status.idle":"2025-07-05T16:55:43.259274Z","shell.execute_reply.started":"2025-07-05T16:55:43.254769Z","shell.execute_reply":"2025-07-05T16:55:43.258643Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# this code is just for texting - will not take it forward\nface_one = all_faces[1000]\nreshaped=face_one.reshape(100,100)\n# reshaped.shape\nfig,ax=plt.subplots(figsize=(5,5))\nax.imshow(reshaped,cmap='gray')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T17:54:49.487660Z","iopub.execute_input":"2025-07-05T17:54:49.487954Z","iopub.status.idle":"2025-07-05T17:54:49.604717Z","shell.execute_reply.started":"2025-07-05T17:54:49.487932Z","shell.execute_reply":"2025-07-05T17:54:49.603996Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Data Splitting - Train&Test\n\nfrom sklearn.model_selection import train_test_split\n\n# X: all_faces as NumPy array (already flattened)\n# y: encoded labels\n\nfrom sklearn.preprocessing import LabelEncoder\n\n# Re-initialize label encoder\nle = LabelEncoder()\ny = le.fit_transform(labels)  # labels = list of student_ids like '01', '02', etc.\n\nX = np.array(all_faces)\n\n# 80% training, 20% testing\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint(\"Training samples:\", X_train.shape[0])\nprint(\"Testing samples:\", X_test.shape[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T17:35:19.885429Z","iopub.execute_input":"2025-07-05T17:35:19.886009Z","iopub.status.idle":"2025-07-05T17:35:19.908844Z","shell.execute_reply.started":"2025-07-05T17:35:19.885985Z","shell.execute_reply":"2025-07-05T17:35:19.908080Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Model Training\nfrom sklearn.svm import SVC\n\n# Linear SVM works well for high-dimensional data like images\nmodel = SVC(kernel='linear', probability=True)\nmodel.fit(X_train, y_train)\n\nprint(\"Training complete\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T17:35:24.230329Z","iopub.execute_input":"2025-07-05T17:35:24.230603Z","iopub.status.idle":"2025-07-05T17:35:57.270266Z","shell.execute_reply.started":"2025-07-05T17:35:24.230583Z","shell.execute_reply":"2025-07-05T17:35:57.269362Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Model Testing on test data\nfrom sklearn.metrics import accuracy_score\n\ny_pred = model.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\n\nprint(f\"Test Accuracy: {acc:.2%}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T17:39:13.990404Z","iopub.execute_input":"2025-07-05T17:39:13.990989Z","iopub.status.idle":"2025-07-05T17:39:17.011442Z","shell.execute_reply.started":"2025-07-05T17:39:13.990965Z","shell.execute_reply":"2025-07-05T17:39:17.010791Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Getting the confusion matrix to visualize how did the model perform on test data\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\ncm = confusion_matrix(y_test, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\ndisp.plot(cmap='Blues', xticks_rotation=45)\nplt.title(\"Confusion Matrix\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T17:40:06.457363Z","iopub.execute_input":"2025-07-05T17:40:06.457921Z","iopub.status.idle":"2025-07-05T17:40:06.808781Z","shell.execute_reply.started":"2025-07-05T17:40:06.457888Z","shell.execute_reply":"2025-07-05T17:40:06.808049Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# To manually check each face\ndef predict_face(img_path):\n    img = cv2.imread(img_path)\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n\n    if len(faces) == 0:\n        print(\"No face detected.\")\n        return\n    \n    (x, y, w, h) = faces[0]\n    face = gray[y:y+h, x:x+w]\n    face = cv2.resize(face, (100, 100)).flatten().reshape(1, -1)\n\n    pred = model.predict(face)\n    prob = model.predict_proba(face)\n\n    student_id = le.inverse_transform(pred)[0]\n    confidence = np.max(prob)\n\n    print(f\"Predicted Student: {student_id} (Confidence: {confidence:.2%})\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T17:40:52.525245Z","iopub.execute_input":"2025-07-05T17:40:52.525747Z","iopub.status.idle":"2025-07-05T17:40:52.530666Z","shell.execute_reply.started":"2025-07-05T17:40:52.525705Z","shell.execute_reply":"2025-07-05T17:40:52.529916Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_face('../input/students-images/03/03/frame_00058.jpg')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T17:57:12.909249Z","iopub.execute_input":"2025-07-05T17:57:12.909924Z","iopub.status.idle":"2025-07-05T17:57:13.100333Z","shell.execute_reply.started":"2025-07-05T17:57:12.909900Z","shell.execute_reply":"2025-07-05T17:57:13.099736Z"}},"outputs":[],"execution_count":null}]}